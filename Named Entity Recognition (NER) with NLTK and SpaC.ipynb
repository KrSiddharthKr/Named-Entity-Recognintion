{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51af0912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\krsid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\krsid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\krsid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\krsid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5aa4c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Steve Jobs, the co-founder of Apple Inc., introduced the first iPhone in 2007.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5771da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person Names: ['Steve', 'Jobs']\n",
      "Organization Names: ['Apple']\n"
     ]
    }
   ],
   "source": [
    "# Pattern matching for person and organization names\n",
    "person_names = []\n",
    "org_names = []\n",
    "for token, pos in pos_tags:\n",
    "    if pos.startswith('NNP'):\n",
    "        if token == 'Jobs' or token == 'Steve':\n",
    "            person_names.append(token)\n",
    "        elif token == 'Apple':\n",
    "            org_names.append(token)\n",
    "\n",
    "print(\"Person Names:\", person_names)\n",
    "print(\"Organization Names:\", org_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "318e9fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Jordan   PERSON\n",
      "the Chicago Bulls ORG\n",
      "Florida          GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Michael Jordan, a former basketball player for the Chicago Bulls, now resides in Florida.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:{16}} {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4bd13ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc.       ORG\n",
      "iPhone           ORG\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text1 = \"Apple Inc. released a new iPhone model.\"\n",
    "text2 = \"I ate a juicy apple for breakfast.\"\n",
    "\n",
    "doc1 = nlp(text1)\n",
    "doc2 = nlp(text2)\n",
    "\n",
    "for ent in doc1.ents:\n",
    "    print(f\"{ent.text:{16}} {ent.label_}\")\n",
    "\n",
    "for ent in doc2.ents:\n",
    "    print(f\"{ent.text:{16}} {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3768f675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'apple' and 'company': 0.07217501103878021\n",
      "Similarity between 'apple' and 'fruit': 0.6410146951675415\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained word vectors\n",
    "wv = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Calculate similarity between words\n",
    "sim = wv.similarity('apple', 'company')\n",
    "print(f\"Similarity between 'apple' and 'company': {sim}\")\n",
    "\n",
    "sim = wv.similarity('apple', 'fruit')\n",
    "print(f\"Similarity between 'apple' and 'fruit': {sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0fa3986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Entities:\n",
      "Elvis            PERSON-ARTIST\n",
      "Presley          PERSON-ARTIST\n",
      "Barack           PERSON-POLITICIAN\n",
      "Obama            PERSON-POLITICIAN\n"
     ]
    }
   ],
   "source": [
    "text = \"Elvis Presley, the legendary musician, and Barack Obama, the former US President, were both influential figures.\"\n",
    "\n",
    "# Tokenize and perform part-of-speech tagging\n",
    "tokens = nltk.word_tokenize(text)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "# Define fine-grained entity categories\n",
    "entities = []\n",
    "for token, pos in pos_tags:\n",
    "    if pos.startswith('NNP'):\n",
    "        if token == 'Elvis' or token == 'Presley':\n",
    "            entities.append(('PERSON-ARTIST', token))\n",
    "        elif token == 'Barack' or token == 'Obama':\n",
    "            entities.append(('PERSON-POLITICIAN', token))\n",
    "\n",
    "print(\"Identified Entities:\")\n",
    "for entity in entities:\n",
    "    print(f\"{entity[1]:{16}} {entity[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ea67f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elvis Presley    PERSON-ARTIST\n",
      "Barack Obama     PERSON-ARTIST\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Elvis Presley, the legendary musician, and Barack Obama, the former US President, were both influential figures.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PERSON':\n",
    "        if 'musician' in ent.sent.text.lower():\n",
    "            print(f\"{ent.text:{16}} PERSON-ARTIST\")\n",
    "        elif 'president' in ent.sent.text.lower():\n",
    "            print(f\"{ent.text:{16}} PERSON-POLITICIAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7222403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Entities:\n",
      "Michael Jordan   PERSON\n",
      "the Chicago Bulls ORG\n",
      "NBA              ORG\n",
      "\n",
      "Spanish Entities:\n",
      "Lionel Messi     PER\n",
      "Barcelona        ORG\n",
      "La Liga          ORG\n"
     ]
    }
   ],
   "source": [
    "# Load English and Spanish NER models\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "nlp_es = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# English text\n",
    "text_en = \"Michael Jordan played for the Chicago Bulls in the NBA.\"\n",
    "doc_en = nlp_en(text_en)\n",
    "\n",
    "print(\"English Entities:\")\n",
    "for ent in doc_en.ents:\n",
    "    print(f\"{ent.text:{16}} {ent.label_}\")\n",
    "\n",
    "# Spanish text\n",
    "text_es = \"Lionel Messi juega para el Barcelona en La Liga.\"\n",
    "doc_es = nlp_es(text_es)\n",
    "\n",
    "print(\"\\nSpanish Entities:\")\n",
    "for ent in doc_es.ents:\n",
    "    print(f\"{ent.text:{16}} {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f8e903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities in line: Michael Jordan played for the Chicago Bulls in the NBA.\n",
      "  Michael          PERSON\n",
      "  Jordan           PERSON\n",
      "Entities in line: Lionel Messi plays for Paris Saint-Germain in Ligue 1.\n",
      "  Lionel           PERSON\n",
      "  Paris            PERSON\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "# Load pre-trained NER tagger\n",
    "# tagger = nltk.data.load('chunkers/maxent_ne_chunker/english.bin')\n",
    "\n",
    "# Open file for simulating text stream\n",
    "# with open('text_stream.txt', 'r') as f:\n",
    "#     for line in f:\n",
    "#         # Tokenize and perform part-of-speech tagging\n",
    "#         tokens = nltk.word_tokenize(line)\n",
    "#         pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "#         # Perform NER\n",
    "#         entities = tagger.parse(pos_tags)\n",
    "\n",
    "#         # Print identified entities\n",
    "#         print(\"Entities in line:\", line)\n",
    "#         for entity in entities:\n",
    "#             if isinstance(entity, nltk.tree.Tree):\n",
    "#                 if entity.label() == 'PERSON':\n",
    "#                     print(f\"  {' '.join(c[0] for c in entity):{16}} {entity.label()}\")\n",
    "\n",
    "\n",
    "# Simulated text stream as a list of strings\n",
    "text_stream = [\n",
    "    \"Michael Jordan played for the Chicago Bulls in the NBA.\",\n",
    "    \"Lionel Messi plays for Paris Saint-Germain in Ligue 1.\"\n",
    "]\n",
    "\n",
    "# Process each line in the simulated text stream\n",
    "for line in text_stream:\n",
    "    # Tokenize and perform part-of-speech tagging\n",
    "    tokens = word_tokenize(line)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    # Perform NER\n",
    "    entities = ne_chunk(pos_tags)\n",
    "\n",
    "    # Print identified entities\n",
    "    print(\"Entities in line:\", line)\n",
    "    for entity in entities:\n",
    "        if isinstance(entity, nltk.Tree):\n",
    "            if entity.label() == 'PERSON':\n",
    "                print(f\"  {' '.join(c[0] for c in entity):{16}} {entity.label()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c9f52b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities (NLTK) in line: Michael Jordan played for the Chicago Bulls in the NBA.\n",
      "  Michael          PERSON\n",
      "  Jordan           PERSON\n",
      "Entities (SpaCy) in line: Michael Jordan played for the Chicago Bulls in the NBA.\n",
      "  Michael Jordan   PERSON\n",
      "  the Chicago Bulls ORG\n",
      "  NBA              ORG\n",
      "Entities (NLTK) in line: Lionel Messi plays for Paris Saint-Germain in Ligue 1.\n",
      "  Lionel           PERSON\n",
      "  Paris            PERSON\n",
      "Entities (SpaCy) in line: Lionel Messi plays for Paris Saint-Germain in Ligue 1.\n",
      "  Messi            PERSON\n",
      "  Paris Saint-Germain ORG\n",
      "  Ligue 1          GPE\n"
     ]
    }
   ],
   "source": [
    "# # Load NER model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Open file for simulating text stream\n",
    "# with open('text_stream.txt', 'r') as f:\n",
    "#     for line in f:\n",
    "#         doc = nlp(line)\n",
    "\n",
    "#         # Print identified entities\n",
    "#         print(\"Entities in line:\", line)\n",
    "#         for ent in doc.ents:\n",
    "#             print(f\"  {ent.text:{16}} {ent.label_}\")\n",
    "\n",
    "\n",
    "# Load NER model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for line in text_stream:\n",
    "    # Tokenize and perform part-of-speech tagging\n",
    "    tokens = word_tokenize(line)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    # Perform NER with NLTK\n",
    "    entities = ne_chunk(pos_tags)\n",
    "\n",
    "    # Print identified entities with NLTK\n",
    "    print(\"Entities (NLTK) in line:\", line)\n",
    "    for entity in entities:\n",
    "        if isinstance(entity, nltk.Tree):\n",
    "            if entity.label() == 'PERSON':\n",
    "                print(f\"  {' '.join(c[0] for c in entity):{16}} {entity.label()}\")\n",
    "\n",
    "    # Perform NER with SpaCy\n",
    "    doc = nlp(line)\n",
    "\n",
    "    # Print identified entities with SpaCy\n",
    "    print(\"Entities (SpaCy) in line:\", line)\n",
    "    for ent in doc.ents:\n",
    "        print(f\"  {ent.text:{16}} {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971870c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
